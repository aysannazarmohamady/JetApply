import requests
from bs4 import BeautifulSoup
import re

def fetch_data_by_url(url: str):
    # Send a GET request to the URL
    response = requests.get(url)
    msg = ""
    telegrammessage = ""  # Initialize the telegrammessage variable

    # Parse the HTML content using BeautifulSoup
    soup = BeautifulSoup(response.content, "html.parser")

    # Find all <a> tags with href attribute
    a_tags = soup.find_all("a", href=True)

    # Process the href values containing "phd"
    for a_tag in a_tags:
        href = a_tag["href"]
        if "phd" in href.lower():
            full_url = base_url + href
            #print(f"Opening URL: {full_url}")

            # Fetch the content of the new URL
            page_response = requests.get(full_url)
            page_soup = BeautifulSoup(page_response.content, "html.parser")

            # Find the meta property="og:title" content
            meta_title = page_soup.find("meta", property="og:title")
            if meta_title:
                meta_title_content = meta_title.get("content", "No title found")
            else:
                meta_title_content = "No title found"

            # Find all occurrences of "Dr." or "Prof."
            page_content = str(page_soup)
            dr_occurrences = set()
            prof_occurrences = set()

            for match in re.finditer(r"Dr\.\s+(\w+\s+\w+)", page_content):
                joined_words = match.group(1)
                dr_occurrences.add(joined_words)

            for match in re.finditer(r"Prof\.\s+(\w+\s+\w+)", page_content):
                joined_words = match.group(1)
                prof_occurrences.add(joined_words)

            # Generate LinkedIn URLs
            linkedin_base_url = "https://www.linkedin.com/search/results/all/"
            linkedin_links = []

            for name in dr_occurrences.union(prof_occurrences):
                first_name, last_name = name.split()
                linkedin_query = f"?keywords={first_name}%20{last_name}&origin=GLOBAL_SEARCH_HEADER"
                linkedin_full_url = linkedin_base_url + linkedin_query
                linkedin_links.append(linkedin_full_url)

            # Find the paragraph containing "@"
            paragraphs = page_soup.find_all("p")
            paragraph_with_at = None
            for paragraph in paragraphs:
                paragraph_text = paragraph.get_text()
                if "@" in paragraph_text:
                    paragraph_with_at = paragraph_text
                    break

            # Find the deadline date
            deadline_date = page_soup.find("td", class_="_Meta_deadline_1ARaM9Ps")

            if deadline_date:
                deadline_date_text = deadline_date.get_text(strip=True)
            else:
                deadline_date_text = "No deadline date found"

            # Find the university name
            university_name = page_soup.find("p", class_="_Employer_name_FD6aOwri")
            if university_name:
                university_name_text = university_name.get_text(strip=True)
            else:
                university_name_text = "University name not found"

            if dr_occurrences or prof_occurrences or paragraph_with_at or deadline_date_text:
                print(f"Position Title: {meta_title_content}")
                msg += f"Position Title: {meta_title_content}" + "\n"
                telegrammessage += f"Position Title: {meta_title_content}" + "\n"  # Add the position title to the telegrammessage

                if dr_occurrences:
                    print("Name of Dr.: ", end="")
                    dr_occurrences_str = ", ".join(dr_occurrences)
                    print(dr_occurrences_str)
                    telegrammessage += f"Name of Dr.: {dr_occurrences_str}" + "\n"  # Add the Dr. names to the telegrammessage
                if prof_occurrences:
                    print("Name of Prof.: ", end="")
                    prof_occurrences_str = ", ".join(prof_occurrences)
                    print(prof_occurrences_str)
                    telegrammessage += f"Name of Prof.: {prof_occurrences_str}" + "\n"  # Add the Prof. names to the telegrammessage
                if paragraph_with_at:
                    print("Email Information:")
                    print(paragraph_with_at)
                    telegrammessage += f"Email Information: {paragraph_with_at}" + "\n"  # Add the email information to the telegrammessage

                if linkedin_links:
                    print("LinkedIn Profiles:")
                    for link in linkedin_links:
                        print(link)
                        telegrammessage += f"LinkedIn Profile: {link}" + "\n"  # Add the LinkedIn profile links to the telegrammessage

                print(f"Deadline Date: {deadline_date_text}")
                telegrammessage += f"Deadline Date: {deadline_date_text}" + "\n"  # Add the deadline date to the telegrammessage
                print(f"University Name: {university_name_text}")  # Print the university name
                telegrammessage += f"University Name: {university_name_text}" + "\n"  # Add the university name to the telegrammessage
            else:
                print(f"Position Title: {meta_title_content}")
                print("'Dr.', 'Prof.', paragraph with '@', word before 'university', or deadline date not found in the page content.")
                telegrammessage += f"Position Title: {meta_title_content}" + "\n"
                telegrammessage += "'Dr.', 'Prof.', paragraph with '@', word before 'university', or deadline date not found in the page content." + "\n"

            print("-" * 30)
            telegrammessage += "-" * 30 + "\n"  # Add a separator line to the telegrammessage

    # Print the telegrammessage
    print(telegrammessage)

# Base URL
base_url = "https://www.academictransfer.com"
tokrn = ""
chatid = ""

# URL to fetch
words = ["ai", "network", "math"]
for word in words:
    for i in range(1, 3):
        url = f"https://www.academictransfer.com/en/jobs/?vacancy_type=scientific&q={word}&function_types=1&order={i}"
        fetch_data_by_url(url)
